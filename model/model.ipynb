{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV3 Model Implementation\n",
    "\n",
    "The following implements a YoloV3 model using a resnet as its base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "from PIL import Image\n",
    "\n",
    "from yaml import load, dump\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "sys.path.append(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment_data import augment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    \n",
    "    def __init__(self, params = {}):\n",
    "        self.num_epochs            = params.get(\"num_epochs\", 100)                   # Number of epochs to train for\n",
    "        self.epoch_start           = params.get(\"epoch_start\", 0)                    # Start counting epochs from this number\n",
    "        self.batch_size            = params.get(\"batch_size\", 1)                     # Number of images in each batch\n",
    "        self.checkpoint_step       = params.get(\"checkpoint_step\", 2)                # How often to save checkpoints (epochs)\n",
    "        self.validation_step       = params.get(\"validation_step\", 2)                # How often to perform validation (epochs)\n",
    "        self.num_validation        = params.get(\"num_validation\", 1000)              # How many validation images to use\n",
    "        self.num_workers           = params.get(\"num_workers\", 4)                    # Number of workers\n",
    "        self.learning_rate         = params.get(\"learning_rate\", 0.045)              # learning rate used for training\n",
    "        self.cuda                  = params.get(\"cuda\", \"0\")                         # GPU ids used for training  \n",
    "        self.use_gpu               = params.get(\"use_gpu\", True)                     # whether to user gpu for training\n",
    "        self.pretrained_model_path = params.get(\"pretrained_model_path\", None)       # path to pretrained model\n",
    "        self.save_model_path       = params.get(\"save_model_path\", \"./.checkpoints\") # path to save model\n",
    "        self.log_file              = params.get(\"log_file\", \"./train.log\")           # path to log file\n",
    "\n",
    "        self.use_gpu = self.use_gpu and torch.cuda.is_available()\n",
    "        \n",
    "if os.path.isfile(\"params.yml\"):\n",
    "    with open(\"params.yml\") as file:\n",
    "        params = Parameters(load(file, Loader=Loader))\n",
    "else:\n",
    "    params = Parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "See the [data augmentation notebook](https://github.com/antoniojkim/WheresWaldo-YoloV3/blob/master/data/data.ipynb) for more details on how the data was curated and augmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20200422)\n",
    "data = augment_data(augment_times=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, data, mode=\"train\"):\n",
    "        assert mode in (\"train\", \"test\")\n",
    "        self.data = data\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.to_tensor = torchv.transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == \"test\":\n",
    "            train = self.to_tensor(\n",
    "                self.data[index][\"image\"][y:y+h, x:x+w]\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            dims = self.data[index][\"crop\"]\n",
    "            x, y, w, h = dims['x'], dims['y'], dims['w'], dims['h']\n",
    "            train = self.to_tensor(\n",
    "                self.data[index][\"image\"][y:y+h, x:x+w]\n",
    "            )\n",
    "        \n",
    "        labels = []\n",
    "        if \"box\" in self.data[index]:\n",
    "            box = data[index]['box']\n",
    "            x, y, w, h = box['x'], box['y'], box['w'], box['h']\n",
    "            labels.append((x + w // 2, y + h // 2, w, h))\n",
    "        \n",
    "        return train, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    Dataset(data, mode=\"train\"),\n",
    "    batch_size  = params.batch_size,\n",
    "    num_workers = params.num_workers,\n",
    "    shuffle     = True,\n",
    "    drop_last   = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    Dataset(data, mode=\"test\"),\n",
    "    batch_size  = params.batch_size,\n",
    "    num_workers = params.num_workers,\n",
    "    shuffle     = True,\n",
    "    drop_last   = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = torchv.models.resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.require_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.resnet(x)\n",
    "        return output\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.use_gpu:\n",
    "    model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parameters = np.sum(np.fromiter((p.numel() for p in model.parameters()), dtype=np.int32))\n",
    "num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1447, 2287])\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(train_dataloader):\n",
    "    print(images.shape)\n",
    "    output = model.forward(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 s ± 57.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    output = model.forward(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
